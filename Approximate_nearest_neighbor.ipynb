{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approximate nearest neighbor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8FkAJgymulmAaYBDYTxdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Kamtekar/Approximate-nearest-neighbor/blob/main/Approximate_nearest_neighbor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUqG1bmH6px6"
      },
      "source": [
        "importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQj5hual6uK4"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es-cVRws6x7e"
      },
      "source": [
        "Importing the lightfm library to import the dataset.\n",
        "First we need to install the library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEA8w1p762FG",
        "outputId": "32464326-6792-4753-d67c-ebef99ea1518"
      },
      "source": [
        "pip install lightfm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.7/dist-packages (1.16)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLBjHq97BjM"
      },
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.evaluation import auc_score"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfqyNbuS7Joq"
      },
      "source": [
        "importing the movielens dataset and getting the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC3i3IXF7MrH"
      },
      "source": [
        "movie_lens = fetch_movielens()\n",
        "\n",
        "train = movie_lens['train']\n",
        "test = movie_lens['test']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwuCOH_Y7xCQ"
      },
      "source": [
        "There are 2 models that lightfm uses and we will use both to see which one is better.\n",
        "\n",
        "1. let us train the model using Bayesian Personalised Ranking (bpr) and look at its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuvjI93R7z-k",
        "outputId": "f2e202ed-34f3-444f-936f-4baec30baa6f"
      },
      "source": [
        "model = LightFM(learning_rate=0.05, loss='bpr')\n",
        "model.fit(train, epochs=10)\n",
        "\n",
        "bpr_precision_train = precision_at_k(model, train, k=10).mean()\n",
        "bpr_precision_test = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
        "\n",
        "bpr_auc_train = auc_score(model, train).mean()\n",
        "bpr_auc_test = auc_score(model, test, train_interactions=train).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (bpr_precision_train, bpr_precision_test))\n",
        "print('AUC: train %.2f, test %.2f.' % (bpr_auc_train, bpr_auc_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.58, test 0.19.\n",
            "AUC: train 0.89, test 0.88.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9OUwQ8VAHZA"
      },
      "source": [
        "2. Now, let us train the model using Weighted Approximate-Rank Pairwise (warp) and look at its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwlgW_v_Rt7",
        "outputId": "890b0f2d-fce2-4d82-fcc1-e73b2f495e5a"
      },
      "source": [
        "model = LightFM(learning_rate=0.05, loss='warp')\n",
        "model.fit_partial(train, epochs=10)\n",
        "\n",
        "warp_precision_train = precision_at_k(model, train, k=10).mean()\n",
        "warp_precision_test = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
        "\n",
        "warp_auc_train = auc_score(model, train).mean()\n",
        "warp_auc_test = auc_score(model, test, train_interactions=train).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (warp_precision_train, warp_precision_test))\n",
        "print('AUC: train %.2f, test %.2f.' % (warp_auc_train, warp_auc_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.59, test 0.22.\n",
            "AUC: train 0.93, test 0.93.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utpj9llwAMI7"
      },
      "source": [
        "we can clearly get slightly higher precision in warp than bpr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjiApvb7A_UZ",
        "outputId": "7d2a66c0-ef86-496f-a4db-70cdaf8a0eec"
      },
      "source": [
        "item_vectors = movie_lens['item_features'] * model.item_embeddings\n",
        "item_vectors"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.63929015, -0.7866718 ,  0.43742874, ...,  0.35012692,\n",
              "        -0.72927636, -0.6804868 ],\n",
              "       [-0.4790248 , -0.6651845 ,  0.5624019 , ..., -0.1497676 ,\n",
              "        -0.31768283, -0.23793122],\n",
              "       [ 0.28179494, -0.3991553 ,  0.14451884, ..., -0.57597595,\n",
              "        -0.39641306,  0.02813605],\n",
              "       ...,\n",
              "       [-0.093698  ,  0.26761952, -0.44490165, ..., -0.2473825 ,\n",
              "         0.37607962,  0.52969223],\n",
              "       [-0.21398911,  0.25069958, -0.33324805, ..., -0.2502132 ,\n",
              "         0.325372  ,  0.39941004],\n",
              "       [-0.12749988,  0.19779742, -0.3461629 , ..., -0.42742547,\n",
              "         0.13021772,  0.2841133 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3XBv4yzBJ6R"
      },
      "source": [
        "let us store this data in a variable.\n",
        "and also save it in a pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElFo-8n4BJEW",
        "outputId": "3dd8a0cf-4f4d-4dd2-8752-3c3ee2597350"
      },
      "source": [
        "with open('movie_lens.pickle', 'wb') as f:\n",
        "    pickle.dump({\"name\": movie_lens['item_feature_labels'], \"vector\": item_vectors}, f)\n",
        "\n",
        "data = ({\"name\": movie_lens['item_feature_labels'], \"vector\": item_vectors})\n",
        "data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[ 0.63929015, -0.7866718 ,  0.43742874, ...,  0.35012692,\n",
              "         -0.72927636, -0.6804868 ],\n",
              "        [-0.4790248 , -0.6651845 ,  0.5624019 , ..., -0.1497676 ,\n",
              "         -0.31768283, -0.23793122],\n",
              "        [ 0.28179494, -0.3991553 ,  0.14451884, ..., -0.57597595,\n",
              "         -0.39641306,  0.02813605],\n",
              "        ...,\n",
              "        [-0.093698  ,  0.26761952, -0.44490165, ..., -0.2473825 ,\n",
              "          0.37607962,  0.52969223],\n",
              "        [-0.21398911,  0.25069958, -0.33324805, ..., -0.2502132 ,\n",
              "          0.325372  ,  0.39941004],\n",
              "        [-0.12749988,  0.19779742, -0.3461629 , ..., -0.42742547,\n",
              "          0.13021772,  0.2841133 ]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP7768GzDQOH"
      },
      "source": [
        "# **Locality Sensitive Hashing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR8Z7H6FDXxt"
      },
      "source": [
        "lets install faiss and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Acvws-Dbo-",
        "outputId": "bec4d7e8-4dbc-402f-b3d0-44e19e251a71"
      },
      "source": [
        "!pip install faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh2ZvWHYXGMk"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX__OJP3DjEe"
      },
      "source": [
        "class LSHIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self, num_bits=8):\n",
        "        self.index = faiss.IndexLSH(self.dimension, num_bits)\n",
        "        self.index.add(self.vectors)\n",
        "          \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6qv4aIUvBBq"
      },
      "source": [
        "Let us calculate the time taken for the model to train using LSH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjmdyoflDvPS",
        "outputId": "1a1df313-ebaa-460b-d93a-6214ea66a1e2"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "index = LSHIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()\n",
        "\n",
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"LSH took {total_time} seconds.\".format(total_time=total_time))\n",
        "\n",
        "print(f\"The most similar movies to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSH took 0.003084421157836914 seconds.\n",
            "The most similar movies to Nightmare Before Christmas, The (1993) are:\n",
            "* Maverick (1994)\n",
            "* Muppet Treasure Island (1996)\n",
            "* Jurassic Park (1993)\n",
            "* Lion King, The (1994)\n",
            "* Sleepless in Seattle (1993)\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Aladdin (1992)\n",
            "* Dances with Wolves (1990)\n",
            "* Mask, The (1994)\n",
            "* While You Were Sleeping (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP0Bs-FdEeVz"
      },
      "source": [
        "# **Exhaustive Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TAUTURxXL7T"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLWgCF9hEft5"
      },
      "source": [
        "class ExhaustiveIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self):\n",
        "        self.index = faiss.IndexFlatL2(self.dimension,)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZDQewL_vLxf"
      },
      "source": [
        "Let us calculate the time taken for the model to train using exhaustive search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rco46A7-HMej",
        "outputId": "4a93b4f4-570f-4c5c-d55e-caa9b9a677fd"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "index = ExhaustiveIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()\n",
        "\n",
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"Exhaustive search took {total_time} seconds.\".format(total_time=total_time))\n",
        "\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exhaustive search took 0.0008196830749511719 seconds.\n",
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Mask, The (1994)\n",
            "* Man Without a Face, The (1993)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Maverick (1994)\n",
            "* Cinderella (1950)\n",
            "* Client, The (1994)\n",
            "* Grease (1978)\n",
            "* Sneakers (1992)\n",
            "* Tombstone (1993)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhRINlXISD_"
      },
      "source": [
        "# **Product Quantization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGYVtVM7XMi-"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj64iHLGIbEH"
      },
      "source": [
        "class IVPQIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimention)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, self.dimention, number_of_partition, search_in_x_partitions, subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "\n",
        "\n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T25TM3nevQLH"
      },
      "source": [
        "Let us calculate the time taken for the model to train using product quantization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADF_j_oAIp8x",
        "outputId": "025fcc8d-ea4d-4187-956e-cd58f3d09366"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "index = IVPQIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()\n",
        "\n",
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"Product Quantization took {total_time} seconds.\".format(total_time=total_time))\n",
        "\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Quantization took 0.10459399223327637 seconds.\n",
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Mask, The (1994)\n",
            "* Cinderella (1950)\n",
            "* Maverick (1994)\n",
            "* Man Without a Face, The (1993)\n",
            "* So I Married an Axe Murderer (1993)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Tombstone (1993)\n",
            "* Grease (1978)\n",
            "* Batman (1989)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPxKv7kJT43"
      },
      "source": [
        "# **Trees and Graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urnxPeCSJzQI"
      },
      "source": [
        "lets install annoy and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxauHp98JyY4",
        "outputId": "6ffc983c-93fb-4d88-9eb5-30a8b29d0dd3"
      },
      "source": [
        "!pip install annoy\n",
        "import annoy"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 102 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 122 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 143 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 646 kB 35.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=391677 sha256=03c71a195149acaf6408374adfb9cb995d17bae6510e1e3ac48db69d245c534c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0u6UFdXN7Z"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urBH1mMrJW0r"
      },
      "source": [
        "class AnnoyIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "\n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        return [self.labels[i] for i in indices]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L7jyV28vUvf"
      },
      "source": [
        "Let us calculate the time taken for the model to train using trees & graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO2jI5DrKGX8",
        "outputId": "f0c202ab-8dac-4bf8-ada2-6d23ddf87148"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "index = AnnoyIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()\n",
        "\n",
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "similar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"Trees and Graph took {total_time} seconds.\".format(total_time=total_time))\n",
        "\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees and Graph took 0.018578529357910156 seconds.\n",
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Mask, The (1994)\n",
            "* Cinderella (1950)\n",
            "* Maverick (1994)\n",
            "* Man Without a Face, The (1993)\n",
            "* So I Married an Axe Murderer (1993)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Tombstone (1993)\n",
            "* Grease (1978)\n",
            "* Batman (1989)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2QQPYlLKp-1"
      },
      "source": [
        "# **Hierarchical Navigable Small World Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0WFZtNxK4x2"
      },
      "source": [
        "lets install nmslib and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrIIWaltK5C6",
        "outputId": "90e0e1f6-457e-42ff-8a59-c3b936d43ad7"
      },
      "source": [
        "!pip install nmslib\n",
        "import nmslib"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nmslib\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n",
            "Installing collected packages: pybind11, nmslib\n",
            "Successfully installed nmslib-2.1.1 pybind11-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrKsrhxSXOnn"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCTxc_LJ3cC"
      },
      "source": [
        "class HNSWIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "\n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d97e5ALvXoM"
      },
      "source": [
        "Let us calculate the time taken for the model to train using HNSW."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqsopTM_K0gU",
        "outputId": "9fdf52b0-d7b4-4406-fda4-39972072ab09"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "index = HNSWIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()\n",
        "\n",
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"HNSW took {total_time} seconds.\".format(total_time=total_time))\n",
        "\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HNSW took 0.23832941055297852 seconds.\n",
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Batman (1989)\n",
            "* Client, The (1994)\n",
            "* Grease (1978)\n",
            "* Mask, The (1994)\n",
            "* Nell (1994)\n",
            "* Man Without a Face, The (1993)\n",
            "* Maverick (1994)\n",
            "* Cinderella (1950)\n",
            "* Sleepless in Seattle (1993)\n"
          ]
        }
      ]
    }
  ]
}