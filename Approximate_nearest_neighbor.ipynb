{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approximate nearest neighbor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOdA261LNbTxMru5zka+oX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Kamtekar/Approximate-nearest-neighbor/blob/main/Approximate_nearest_neighbor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUqG1bmH6px6"
      },
      "source": [
        "importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQj5hual6uK4"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es-cVRws6x7e"
      },
      "source": [
        "Importing the lightfm library to import the dataset.\n",
        "First we need to install the library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEA8w1p762FG",
        "outputId": "66145800-e3ac-4d4c-fd04-15b6931bdf87"
      },
      "source": [
        "pip install lightfm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.7/dist-packages (1.16)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLBjHq97BjM"
      },
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.evaluation import auc_score"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfqyNbuS7Joq"
      },
      "source": [
        "importing the movielens dataset and getting the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC3i3IXF7MrH"
      },
      "source": [
        "movie_lens = fetch_movielens()\n",
        "\n",
        "train = movie_lens['train']\n",
        "test = movie_lens['test']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwuCOH_Y7xCQ"
      },
      "source": [
        "There are 2 models that lightfm uses and we will use both to see which one is better.\n",
        "\n",
        "1. let us train the model using Bayesian Personalised Ranking (bpr) and look at its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuvjI93R7z-k",
        "outputId": "371f33ae-0fd8-4fad-ed03-8ae5de9fce14"
      },
      "source": [
        "model = LightFM(learning_rate=0.05, loss='bpr')\n",
        "model.fit(train, epochs=10)\n",
        "\n",
        "bpr_precision_train = precision_at_k(model, train, k=10).mean()\n",
        "bpr_precision_test = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
        "\n",
        "bpr_auc_train = auc_score(model, train).mean()\n",
        "bpr_auc_test = auc_score(model, test, train_interactions=train).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (bpr_precision_train, bpr_precision_test))\n",
        "print('AUC: train %.2f, test %.2f.' % (bpr_auc_train, bpr_auc_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.60, test 0.20.\n",
            "AUC: train 0.90, test 0.88.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9OUwQ8VAHZA"
      },
      "source": [
        "2. Now, let us train the model using Weighted Approximate-Rank Pairwise (warp) and look at its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwlgW_v_Rt7",
        "outputId": "1053bfe2-7049-4bc4-ac16-99b62526c1cb"
      },
      "source": [
        "model = LightFM(learning_rate=0.05, loss='warp')\n",
        "model.fit_partial(train, epochs=10)\n",
        "\n",
        "warp_precision_train = precision_at_k(model, train, k=10).mean()\n",
        "warp_precision_test = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
        "\n",
        "warp_auc_train = auc_score(model, train).mean()\n",
        "warp_auc_test = auc_score(model, test, train_interactions=train).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (warp_precision_train, warp_precision_test))\n",
        "print('AUC: train %.2f, test %.2f.' % (warp_auc_train, warp_auc_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.60, test 0.22.\n",
            "AUC: train 0.93, test 0.93.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utpj9llwAMI7"
      },
      "source": [
        "we can clearly get slightly higher precision in warp than bpr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjiApvb7A_UZ",
        "outputId": "964143bf-bab1-46a7-99ad-e0554a357d0f"
      },
      "source": [
        "item_vectors = movie_lens['item_features'] * model.item_embeddings\n",
        "item_vectors"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.2405493 ,  0.02754697,  0.6042577 , ...,  0.757712  ,\n",
              "         0.06605501,  0.5899007 ],\n",
              "       [ 0.08846308,  0.28421962,  0.55485255, ...,  0.33963293,\n",
              "         0.44817957,  0.38973722],\n",
              "       [-0.16057768,  0.571251  ,  0.13750643, ...,  0.41625515,\n",
              "         0.09895659,  0.23993613],\n",
              "       ...,\n",
              "       [-0.49230114,  0.22580701, -0.510393  , ..., -0.31490573,\n",
              "        -0.58756775, -0.48926398],\n",
              "       [-0.36014026,  0.19565772, -0.26121157, ..., -0.3110757 ,\n",
              "        -0.3958605 , -0.47949326],\n",
              "       [-0.45961455,  0.09483821, -0.3228401 , ..., -0.21541038,\n",
              "        -0.26523745, -0.50422144]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3XBv4yzBJ6R"
      },
      "source": [
        "let us store this data in a variable.\n",
        "and also save it in a pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElFo-8n4BJEW",
        "outputId": "812b7729-7670-46c6-a742-5d54e4e918cb"
      },
      "source": [
        "with open('movie_lens.pickle', 'wb') as f:\n",
        "    pickle.dump({\"name\": movie_lens['item_feature_labels'], \"vector\": item_vectors}, f)\n",
        "\n",
        "data = ({\"name\": movie_lens['item_feature_labels'], \"vector\": item_vectors})\n",
        "data"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[ 0.2405493 ,  0.02754697,  0.6042577 , ...,  0.757712  ,\n",
              "          0.06605501,  0.5899007 ],\n",
              "        [ 0.08846308,  0.28421962,  0.55485255, ...,  0.33963293,\n",
              "          0.44817957,  0.38973722],\n",
              "        [-0.16057768,  0.571251  ,  0.13750643, ...,  0.41625515,\n",
              "          0.09895659,  0.23993613],\n",
              "        ...,\n",
              "        [-0.49230114,  0.22580701, -0.510393  , ..., -0.31490573,\n",
              "         -0.58756775, -0.48926398],\n",
              "        [-0.36014026,  0.19565772, -0.26121157, ..., -0.3110757 ,\n",
              "         -0.3958605 , -0.47949326],\n",
              "        [-0.45961455,  0.09483821, -0.3228401 , ..., -0.21541038,\n",
              "         -0.26523745, -0.50422144]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP7768GzDQOH"
      },
      "source": [
        "# **Locality Sensitive Hashing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR8Z7H6FDXxt"
      },
      "source": [
        "lets install faiss and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Acvws-Dbo-",
        "outputId": "4fc629d0-0383-45c8-fc0b-a9f10100ac38"
      },
      "source": [
        "!pip install faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh2ZvWHYXGMk"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX__OJP3DjEe"
      },
      "source": [
        "class LSHIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self, num_bits=8):\n",
        "        self.index = faiss.IndexLSH(self.dimension, num_bits)\n",
        "        self.index.add(self.vectors)\n",
        "          \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]\n",
        "\n",
        "index = LSHIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjmdyoflDvPS",
        "outputId": "dee8713c-673e-40f1-daa4-80f786aa02e4"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movies to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movies to Nightmare Before Christmas, The (1993) are:\n",
            "* What's Eating Gilbert Grape (1993)\n",
            "* While You Were Sleeping (1995)\n",
            "* Die Hard (1988)\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Fish Called Wanda, A (1988)\n",
            "* Groundhog Day (1993)\n",
            "* Cinderella (1950)\n",
            "* Sound of Music, The (1965)\n",
            "* Searching for Bobby Fischer (1993)\n",
            "* Mr. Holland's Opus (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP0Bs-FdEeVz"
      },
      "source": [
        "# **Exhaustive Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TAUTURxXL7T"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLWgCF9hEft5"
      },
      "source": [
        "class ExhaustiveIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self):\n",
        "        self.index = faiss.IndexFlatL2(self.dimension,)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]\n",
        "\n",
        "\n",
        "index = ExhaustiveIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rco46A7-HMej",
        "outputId": "ec87be75-bbc6-4ff4-b82c-a9646500d411"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Cinderella (1950)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Aladdin (1992)\n",
            "* Princess Bride, The (1987)\n",
            "* Sword in the Stone, The (1963)\n",
            "* Monty Python's Life of Brian (1979)\n",
            "* Interview with the Vampire (1994)\n",
            "* Braveheart (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhRINlXISD_"
      },
      "source": [
        "# **Product Quantization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGYVtVM7XMi-"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj64iHLGIbEH"
      },
      "source": [
        "class IVPQIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimention)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, self.dimention, number_of_partition, search_in_x_partitions, subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "\n",
        "\n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]\n",
        "\n",
        "\n",
        "index = IVPQIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADF_j_oAIp8x",
        "outputId": "efbb3cd4-99e9-4125-fbcd-bd817293daf5"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Cinderella (1950)\n",
            "* Braveheart (1995)\n",
            "* Monty Python's Life of Brian (1979)\n",
            "* Princess Bride, The (1987)\n",
            "* Aladdin (1992)\n",
            "* Abyss, The (1989)\n",
            "* Stand by Me (1986)\n",
            "* Evil Dead II (1987)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPxKv7kJT43"
      },
      "source": [
        "# **Trees and Graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urnxPeCSJzQI"
      },
      "source": [
        "lets install annoy and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxauHp98JyY4",
        "outputId": "7b97e9f0-68b2-40bc-e094-1f5a799d6ae5"
      },
      "source": [
        "!pip install annoy\n",
        "import annoy"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 646 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=391681 sha256=4010ce9aab0e3744a9d22a65a1bdf91d6f7fc293f76e5e973648d40aa8ef05ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0u6UFdXN7Z"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urBH1mMrJW0r",
        "outputId": "98107605-d616-44f3-8600-19b1e4fb0e0b"
      },
      "source": [
        "class AnnoyIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "\n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        return [self.labels[i] for i in indices]\n",
        "\n",
        "\n",
        "index = AnnoyIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO2jI5DrKGX8",
        "outputId": "940db341-7f9a-4e93-a4df-14b090f8e9d4"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "similar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movie to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Cinderella (1950)\n",
            "* Braveheart (1995)\n",
            "* Monty Python's Life of Brian (1979)\n",
            "* Princess Bride, The (1987)\n",
            "* Aladdin (1992)\n",
            "* Abyss, The (1989)\n",
            "* Stand by Me (1986)\n",
            "* Evil Dead II (1987)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2QQPYlLKp-1"
      },
      "source": [
        "# **Hierarchical Navigable Small World Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0WFZtNxK4x2"
      },
      "source": [
        "lets install nmslib and import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrIIWaltK5C6",
        "outputId": "aea32bd3-f57f-437e-8d64-32fac4c13364"
      },
      "source": [
        "!pip install nmslib\n",
        "import nmslib"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nmslib in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.7/dist-packages (from nmslib) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrKsrhxSXOnn"
      },
      "source": [
        "Creating index class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCTxc_LJ3cC"
      },
      "source": [
        "class HNSWIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "\n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[i] for i in indices[0]]\n",
        "\n",
        "\n",
        "index = HNSWIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqsopTM_K0gU",
        "outputId": "11251252-e239-49c3-e7f8-f28853d29607"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "simlar_movie_questions = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar stack to {movie_name} are:\\n* {simlar_movie_questions}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar stack to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Cinderella (1950)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Sword in the Stone, The (1963)\n",
            "* Aladdin (1992)\n",
            "* Interview with the Vampire (1994)\n",
            "* Princess Bride, The (1987)\n",
            "* Monty Python's Life of Brian (1979)\n",
            "* Stand by Me (1986)\n"
          ]
        }
      ]
    }
  ]
}